# 빅데이터와 관련된 개념 정리

## 1. 빅데이터의 정의 및 특징

- **데이터**: 가공되지 않은 사실
- **정보**: 데이터에서 의미를 부여한 결과

### 빅데이터 3V

- **Volume (규모)**: 데이터 양
- **Variety (다양성)**: 데이터 형태 다양
- **Velocity (속도)**: 데이터 처리 속도

### 추가 2V

- **Value (가치)**: 숨겨진 가치 발견
- **Veracity (신뢰성)**: 데이터 품질

---

## 2. DIKW 피라미드

| 단계         | 설명                        |
|--------------|-----------------------------|
| **Data**     | 가공되지 않은 사실          |
| **Information** | 데이터에서 패턴 인식        |
| **Knowledge** | 패턴을 기반으로 예측        |
| **Wisdom**   | 창의적 활용 및 의사결정     |

---

## 3. 암묵지 vs 형식지

| 유형      | 설명                             |
|-----------|----------------------------------|
| **암묵지**  | 개인의 경험, 직관 (눈에 보이지 않음) |
| **형식지**  | 문서화된 지식 (매뉴얼, 교재 등)   |

### 지식 변환 4단계

1. **공통화**: 암묵지 공유
2. **표출화**: 암묵지 문서화
3. **연결화**: 새로운 지식 추가
4. **내면화**: 형식지를 통한 새로운 암묵지 습득

---

## 4. 하둡 코어 (Hadoop Core) 구성 요소

- **HDFS**: 분산 파일 시스템
- **MapReduce**: 분산 데이터 처리 모델
  - **Map**: 데이터를 쪼개어 처리
  - **Reduce**: 데이터를 집계하여 처리
- **YARN**: 리소스 관리 및 작업 스케줄링

---

## 5. MapReduce 주요 패턴

| 패턴       | 설명                     | 예시                                 |
|------------|--------------------------|--------------------------------------|
| **조인**     | 두 데이터셋 결합           | 사용자 정보 + 구매 기록              |
| **그룹화**    | 동일 키로 묶기            | 사용자별 방문 페이지 목록           |
| **단어 카운트** | 빈도 계산                 | 텍스트 내 단어 수                    |
| **통계**     | 평균/합/분산 계산          | 사용자별 구매 금액 평균             |
| **필터링**    | 조건에 맞는 데이터 추출     | 5분 미만 웹 로그 제거                |

---

## 6. 데이터베이스 (DB) 핵심 요소

- **스키마**: 데이터베이스 구조
- **인스턴스**: 데이터 타입과 값
- **메타데이터**: 데이터 설명
- **인덱스**: 빠른 데이터 검색

### DBMS 유형

- **관계형 DBMS**: 테이블 형식
- **NoSQL**: 비정형 데이터 저장

### SQL

- **DDL**: 데이터베이스 정의 (CREATE, ALTER)
- **DML**: 데이터 조작 (SELECT, INSERT)
- **DCL**: 권한 제어 (GRANT, REVOKE)

---

## 7. 기업 활용 데이터베이스 시스템

| 시스템   | 풀 네임                        | 설명                                 |
|----------|---------------------------------|--------------------------------------|
| **OLTP** | Online Transaction Processing   | 실시간 거래 처리 시스템 (예: 은행, 쇼핑몰) |
| **OLAP** | Online Analytical Processing    | 다차원 데이터 분석 시스템 (예: 경영 분석) |
| **CRM**  | Customer Relationship Management | 고객 관계 관리 시스템 (예: 고객 정보 관리) |
| **ERP**  | Enterprise Resource Planning    | 전사적 자원 관리 시스템 (예: 재고, 인사, 회계 관리) |
| **BI**   | Business Intelligence           | 비즈니스 인텔리전스 시스템 (예: 데이터 기반 의사결정 지원) |
| **BA**   | Business Analytics              | 비즈니스 분석 (예: 예측 모델링, 심층 분석) |
| **Blockchain** | Blockchain                  | 분산 원장 기술 (예: 암호화폐, 스마트 계약) |
| **KMS**  | Knowledge Management System     | 지식 관리 시스템 (예: 조직 내 지식 공유) |

---

## 8. 데이터 사이언스 핵심 요소

- **Analytics**: 이론적 지식 (수학, 통계)
- **IT**: 프로그래밍 지식
- **비즈니스**: 비즈니스 문제 해결 능력

### 핵심 역량

- **하드 스킬**: 수학, 통계, 데이터 분석
- **소프트 스킬**: 스토리텔링, 창의성, 리더십

---

## 9. 하둡 에코시스템

| 범주            | 도구               | 설명                            |
|-----------------|--------------------|---------------------------------|
| **데이터 저장**   | HBase              | NoSQL 데이터베이스 (컬럼 기반)   |
| **데이터 수집**   | Flume, Sqoop       | 로그 수집, RDBMS 연동           |
| **데이터 처리**   | Hive, Pig, Spark   | SQL, 스크립트, 인메모리 처리    |
| **워크플로우 관리**| Oozie, Zookeeper   | 작업 스케줄링, 분산 조율        |
| **검색**         | Solr, Lucene       | 검색 및 인덱싱 기능 제공        |

---

## 10. 하둡 코어 vs 하둡 에코시스템

| 구분           | 하둡 코어                          | 하둡 에코시스템                        |
|----------------|------------------------------------|----------------------------------------|
| **역할**        | 저장 및 처리의 핵심 기능            | 고급 기능, 확장성 제공                |
| **구성 요소**   | HDFS, MapReduce, YARN              | Hive, HBase, Spark 등                 |
| **독립 실행**   | 독립적으로 실행 가능                | 하둡 코어 위에서 실행                 |
| **목적**        | 분산 저장 및 처리                   | 실무 활용의 편리성 향상               |

---

## 11. 데이터 단위

| 단위 | 크기                               |
|------|------------------------------------|
| KB   | 1,000 바이트                       |
| MB   | 1,000 KB                           |
| GB   | 1,000 MB                           |
| TB   | 1,000 GB                           |
| PB   | 1,000 TB                           |
| EB   | 1,000 PB                           |
| ZB   | 1,000 EB                           |
| YB   | 1,000 ZB                           |

- 데이터의 크기는 급격히 커지며, 특히 빅데이터 시대에서는 페타바이트(PB), 엑사바이트(EB) 규모의 데이터가 처리됩니다.

---

## 12. 빅데이터 가치 패러다임 변화

1. **Digitalization**: 아날로그 데이터를 디지털화하여 정보화하는 과정.  
   - 예시: 손글씨를 디지털화하거나, 아날로그 비디오를 디지털 파일로 변환하는 것.
2. **Connection**: 디지털화된 데이터들 간의 연결성.  
   - 예시: IoT 장치들이 생성하는 데이터를 클라우드에 저장하여, 서로 연결하고 상호작용하는 방식.
3. **Agency**: 연결된 데이터의 효과적인 관리.  
   - 데이터가 많을수록 관리의 중요성이 커짐. 데이터의 흐름을 제어하고, 의미 있는 통찰을 도출하는 작업.

---

## 13. 빅데이터 조직 및 인력

### 조직 및 인력 방안 수립 (DSCoE: 분석조직)

1. **집중 구조**: 독립적이고 전담 조직을 구성하여 분석 전문성을 집중시킴.
   - 장점: 효율적이고 전문적인 데이터 분석을 할 수 있음.
   - 단점: 중복 업무 발생 가능성, 다른 부서와의 협업 어려움.
   
2. **기능 구조**: 각 부서가 직접 분석 작업을 수행.
   - 장점: 현업과 밀접하게 연관된 데이터 분석이 가능함.
   - 단점: 분석 품질의 일관성 유지 어려움, 전문 인력 부족.
   
3. **분산 구조**: 분석 조직 인력을 각 부서에 배치하여 분산 관리.
   - 장점: 각 부서의 니즈에 맞춘 분석 가능, 빠른 의사결정.
   - 단점: 분석 역량의 분산, 중복된 노력이 발생할 수 있음.

---

## 14. 빅데이터 기술 및 제도

### 빅데이터 플랫폼

빅데이터 플랫폼은 데이터의 수집, 저장, 처리, 분석 등 전 과정을 효율적으로 처리할 수 있도록 설계된 환경입니다. 이 플랫폼은 데이터의 규모가 크고, 복잡한 처리 및 분석을 필요로 하는 작업에 필수적입니다.

### 빅데이터 플랫폼의 계층 구조

1. **소프트웨어 계층**
   - **데이터 수집 및 정제**: 원시 데이터를 수집하고 필요한 형태로 정제하여 저장.
   - **데이터 처리 및 분석**: 수집된 데이터를 분석 및 가공하여 의미 있는 결과를 도출.
   - **사용자/서비스 관리**: 분석 결과를 사용자에게 제공하거나 다른 서비스로 연계.

2. **플랫폼 계층**
   - **데이터 및 자원 관리**: 데이터의 저장, 분배, 보호 등 자원 관리.
   - **작업 스케줄링**: 데이터 처리 및 분석 작업을 효율적으로 스케줄링하고 자동화.
   - **프로파일링**: 데이터 품질 관리 및 최적화 작업.

3. **인프라스트럭쳐 계층**
   - **자원의 배치 및 관리**: 하드웨어 및 클라우드 자원의 배치와 최적화.
   - **저장장치 및 네트워크 관리**: 대규모 데이터를 저장할 수 있는 인프라와 네트워크 관리.

---

## 15. 빅데이터와 인공지능

### 인공지능, 머신러닝, 딥러닝의 관계

- **인공지능 (AI)**: 인간의 사고를 모방하여 문제를 해결하는 기술의 총칭. 예를 들어, 자연어 처리, 이미지 인식, 게임 플레이 등이 포함됨.
- **머신러닝 (ML)**: 인공지능의 하위 분야로, 데이터에서 패턴을 학습하여 예측이나 결정을 내리는 알고리즘.
- **딥러닝 (DL)**: 머신러닝의 하위 분야로, 인공신경망을 사용하여 대량의 데이터를 통해 스스로 학습하고 예측하는 기술. 주로 음성 인식, 이미지 분류 등에서 강력한 성능을 발휘함.

### 머신러닝의 종류

1. **지도학습 (Supervised Learning)**
   - 정답(label)을 알려주고 모델이 그것을 예측하도록 학습.
   - 예시: 이메일 분류 (스팸/비스팸).
   
2. **비지도학습 (Unsupervised Learning)**
   - 정답 없이 데이터를 학습하여 패턴이나 구조를 찾는 방법.
   - 예시: 군집화 (Clustering) 또는 차원 축소 (Dimensionality Reduction).
   
3. **준지도학습 (Semi-supervised Learning)**
   - 일부 데이터에는 정답이 있고, 일부는 정답이 없는 데이터가 혼합된 형태.
   - 예시: 웹사이트의 텍스트 내용 분석에 일부 정답만 사용하고 나머지 데이터를 학습.
   
4. **강화학습 (Reinforcement Learning)**
   - 에이전트가 환경과 상호작용하며 보상을 최적화하는 방법으로 학습.
   - 예시: 알파고 (AlphaGo)와 같은 게임에서 보상을 받기 위해 학습.

### 약인공지능 vs 강인공지능

1. **약인공지능 (Weak AI)**
   - 특정 작업을 수행하는 데 특화된 인공지능. 일반적인 인지 능력은 없음.
   - 예시: 얼굴 인식, 음성 인식, 자율주행의 일부 기능, 추천 시스템 등.
   - **특징**
     - 도메인 한정적
     - 인간 수준의 이해력은 없음

2. **강인공지능 (Strong AI)**
   - 인간과 유사한 수준의 인지 능력을 갖춘 인공지능으로, 자율적인 사고와 학습이 가능.
   - 예시: 인간처럼 창의적 사고를 하고, 자기 인식(self-awareness)을 가진 AI (이론적 존재)
   - **특징**
     - 일반화된 학습 능력
     - 감정, 직관, 추론 가능 (가정상)

3. **초인공지능 (Superintelligence)**
   - 기술적 특이점을 넘어 인간의 모든 지능을 초월하는 AI.
   - 가능성 논의는 활발하나 실현 여부는 불확실.
   - 윤리적, 철학적 문제와 깊은 연관

---

### 경량 딥러닝 학습 기법

1. **전이학습 (Transfer Learning)**
   - 대규모 데이터로 학습된 모델을 새로운 작업에 재사용.
   - 작은 데이터셋에서도 높은 성능 가능.

2. **Fine-Tuning**
   - 전이학습된 모델의 일부 또는 전체 파라미터를 특정 작업에 맞게 추가 학습.
   - Full fine-tuning vs. Partial fine-tuning (예: LoRA, Adapter)

3. **지식증류 (Knowledge Distillation)**
   - 큰 모델(Teacher)의 지식을 작은 모델(Student)에 압축 전달.
   - 속도 및 효율성 향상에 유리.

4. **기타 경량화 기법**
   - **Pruning**: 중요하지 않은 뉴런이나 연결을 제거하여 모델 크기 축소
   - **Quantization**: 모델의 가중치와 연산을 정수형으로 변환해 경량화
   - **Low-Rank Factorization**: 행렬 분해를 통해 연산량 감소

---

### 최신 인공지능 기술동향

1. **AutoML**
   - 모델 선택, 하이퍼파라미터 튜닝, 피처 엔지니어링 등을 자동화
   - 예시: Google AutoML, AutoKeras

2. **MLOps**
   - 머신러닝 시스템의 지속적 통합(CI), 지속적 배포(CD)를 지원하는 운영 기법
   - 구성요소: 데이터 버전 관리, 모델 서빙, 모니터링 등

3. **XAI (eXplainable AI)**
   - 모델의 예측 결과를 사람이 이해할 수 있도록 설명
   - 주요 기술: SHAP, LIME, Attention Visualization

4. **생성형 AI (Generative AI)**
   - 입력 조건에 따라 새로운 텍스트, 이미지, 음성 등을 생성
   - **LLM (Large Language Model)**: GPT, Claude, Gemini 등
   - **Diffusion Models**: Stable Diffusion, DALL·E 등
   - **Multimodal AI**: 텍스트 + 이미지 + 음성 등 복합 입력/출력을 다루는 모델 (예: GPT-4o, Gemini 1.5 Pro)

5. **에이전트형 AI (AI Agents)**
   - LLM 기반 에이전트가 사용자의 명령을 이해하고 작업을 자동으로 수행
   - 예시: AutoGPT, OpenAI GPT Agents, LangChain Agents
   - **특징**
     - 플래너 + 툴 사용 + 멀티스텝 추론
     - 자율적 의사결정 및 API 연동 능력

# 개인정보 법제도

## 1. 데이터 3법

**데이터 3법**은 2020년 개정된 대한민국의 개인정보 관련 3개 법률을 통칭하며, 데이터 산업 활성화와 개인정보 보호의 균형을 도모하기 위해 마련된 법 제도입니다.

### 개인정보 보호법
- 대한민국의 **개인정보 보호에 관한 기본법**.
- 모든 공공기관 및 민간 사업자에게 적용.
- 개인정보의 수집, 이용, 제공, 파기 등에 대한 일반 규범을 규정.
- **개인정보보호위원회**를 중앙 행정기관으로 격상 (2020년 개정).
- 가명정보 활용 및 관련 기준 신설.

### 정보통신망 이용 촉진 및 정보보호 등에 관한 법률 (정보통신망법)
- 정보통신서비스 제공자(포털, SNS 등)의 개인정보 처리 기준을 규정.
- 2020년 개정 이후 개인정보 관련 규정은 대부분 **개인정보 보호법으로 이관**.
- 현재는 정보보호 및 통신망 안정성 관련 내용 중심.

### 신용정보의 이용 및 보호에 관한 법률 (신용정보법)
- 금융권에서의 개인정보(신용정보) 처리에 관한 법률.
- **마이데이터 사업**, **신용정보 자기결정권**, **가명정보 활용** 등 포함.
- 데이터 기반 금융 서비스 활성화 목적.

---

## 2. 데이터 3법 주요 특징

### 가명정보의 개념 도입
- **가명정보**: 개인정보 일부를 삭제·대체하여 원래 개인을 식별할 수 없도록 처리한 정보.
- 통계, 연구, 공익적 기록 보존 목적이라면 **정보주체 동의 없이도 활용 가능**.
- 재식별 금지, 보호조치 필수.

### 개인정보보호위원회 권한 강화
- 중앙행정기관으로 격상되어 **정책 일원화 및 감독권 강화**.
- 기업·기관에 대한 지도, 감독, 제재 기능 수행.

### 데이터 활용과 보호의 균형
- 기존: 보호 중심 규제 → 개정 후: **활용과 보호의 균형** 추구.
- 기업·기관이 **가명정보를 안전하게 활용**할 수 있는 법적 근거 마련.

### 정보주체의 권리 강화
- 정보주체는 자신의 개인정보에 대해:
- **열람, 정정, 삭제, 처리 정지 요청 가능**.
- **마이데이터 제도** 도입:
- 개인이 본인의 정보를 직접 관리·제공 가능.

---

# 개인정보 관련 개념 및 활용 가이드라인 정리

## 1. 개인정보, 가명정보, 익명정보 개념

| 구분       | 정의 | 활용 가능성 | 특징 |
|------------|------|--------------|------|
| **개인정보** | 개인을 식별할 수 있는 정보 (이름, 주민번호, 전화번호 등) | 정보주체 **동의 필요** | 식별 가능성이 있음 |
| **가명정보** | 개인정보의 일부를 삭제·변경하여 **추가 정보 없이는 식별 불가** | 통계·연구·공익 목적 시 **동의 없이 활용 가능** | 재식별 금지, 보호조치 필수 |
| **익명정보** | 더 이상 특정 개인을 **식별할 수 없는 정보** | **제한 없이 자유롭게 활용 가능** | 재식별 불가능 |

---

## 2. 개인정보 비식별 조치 가이드라인

### 비식별화 절차

1. **사전검토**  
   - 개인정보 여부 판단  
   - 비식별 필요성 및 목적 검토  

2. **비식별 조치 방법**
   - **총계처리**: 개별 수치를 집계하여 정보 단순화  
   - **삭제처리**: 식별 가능한 항목 완전 제거  
   - **마스킹**: 일부 정보를 숨기거나 대체 (예: 홍*동, 010-****-1234)

3. **적정성 평가**
   - **k-익명성**: 동일 속성의 레코드가 최소 k개 이상 존재  
   - **l-다양성**: k 그룹 내 민감정보의 다양성 확보  
   - **t-근접성**: 그룹 내 민감정보 분포가 전체 데이터 분포와 유사

4. **사후관리**
   - 재식별 시도 방지  
   - 비식별 조치 이력 관리  
   - 데이터 재활용 시 재검토

---

## 3. 개인정보 활용 시 고려사항

### 위기 요인과 대응 방안

| 위기 요인 | 설명 | 대응 방안 |
|-----------|------|------------|
| **사생활 침해** | SNS나 위치 정보 등이 사생활 침해로 이어질 수 있음 | 정보 제공자에서 **사용자 책임 전환** 필요 |
| **책임 원칙 훼손** | AI가 범죄 예측으로 오판하여 체포 등 인권 침해 우려 | 결과에 대한 **명확한 책임 기준 필요** |
| **데이터 오용** | 분석 결과가 항상 정답이 아님 | 결과 해석 가능한 **전문 인력(알고리즈미스트)** 필요 |

> **알고리즈미스트란?**  
> 알고리즘 오판 등으로 부당한 피해를 입은 사람들을 구제하고,  
> 알고리즘의 해석 가능성과 공정성을 보장하는 **전문 인력**.

---

## 4. 데이터 분석 방안 수립

### 분석 로드맵 설정  
- 분석 목적 → 데이터 수집 → 분석 방법 → 결과 해석 → 실행 방안 도출

### 분석 유형 매트릭스

| 분석 방법 | 분석 대상 | 분석 유형     | 예시 |
|------------|------------|----------------|------|
| Known      | Known      | **최적화 (Optimization)** | 마케팅 비용 최소화 |
| Unknown    | Known      | **솔루션 (Solution)** | 새로운 약 처방 설계 |
| Known      | Unknown    | **통찰 (Insight)** | 고객 행동 패턴 분석 |
| Unknown    | Unknown    | **발견 (Discovery)** | 질병 유전자 탐색 |

---